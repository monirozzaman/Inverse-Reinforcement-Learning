{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import optimize\n",
    "from copy import deepcopy\n",
    "import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "from scipy import math\n",
    "from scipy import linalg\n",
    "import sys\n",
    "import random\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def irl_gradient_ascent(sample_trajectories,feature_matrix,feature_e,scaler,error_term,thre,learning_rate, \\\n",
    "                        base_p,execu_p,show_flag=False,show_count=50):\n",
    "    '''\n",
    "    Relative Entropy Inverse Reinforcement Learning\n",
    "    '''\n",
    "    feature_expectation=feature_e\n",
    "    diff=10000\n",
    "    last_diff=0\n",
    "    n_feature = len(feature_e)\n",
    "    max_fe=[]\n",
    "    for l_fe in feature_matrix.T:\n",
    "        max_fe.append(np.max(l_fe))\n",
    "    theta=np.random.random(size=(n_feature,))\n",
    "    base_vector=np.zeros(n_feature)\n",
    "\n",
    "    prob_ratio=get_prob_ratio_from_policies(sample_trajectories,base_p,execu_p)\n",
    "    loop_counter=0\n",
    "    last_theta=[]\n",
    "    ll_diff=0\n",
    "    back_flag=False\n",
    "    mem_alpha=learning_rate\n",
    "    set_alpha=False\n",
    "\n",
    "    while abs(diff)>thre :\n",
    "        if not back_flag:\n",
    "            last_diff=diff\n",
    "        iterated_rewards=np.dot(theta,feature_matrix.T)+prob_ratio\n",
    "        alphas=theta/np.abs(theta)*error_term\n",
    "        feature_count=np.zeros(n_feature)\n",
    "        sample_importance=0\n",
    "        m_reward=max(iterated_rewards)\n",
    "        ind_re=np.argmax(iterated_rewards)\n",
    "        iterated_rewards-=m_reward+20\n",
    "        for i in range(len(feature_matrix)):\n",
    "            if prob_ratio[i]==0:\n",
    "                continue\n",
    "            try:\n",
    "                feature_count+=math.exp(iterated_rewards[i]) \\\n",
    "                                *feature_matrix[i]\n",
    "                sample_importance+=math.exp(iterated_rewards[i])\n",
    "            except:\n",
    "                print(feature_matrix[i])\n",
    "                print(theta)\n",
    "                print(iterated_rewards[i])\n",
    "                print(prob_ratio[i])\n",
    "                raise(ValueError)\n",
    "        gradient=feature_expectation-feature_count/sample_importance\n",
    "        theta=theta+learning_rate*gradient\n",
    "        t=judge_norm(theta,base_vector,2)\n",
    "        diff=judge_norm(gradient,base_vector,2)\n",
    "        \n",
    "        if loop_counter%show_count==0 and show_flag:\n",
    "            print(loop_counter, diff)\n",
    "            print('reward',m_reward)\n",
    "            print('fe',feature_count/sample_importance)\n",
    "            print('differ',abs(diff-last_diff))\n",
    "            print('theta',theta)\n",
    "            print('grad',gradient)\n",
    "            print('    ')\n",
    "        loop_counter+=1\n",
    "        if loop_counter>=5000000:\n",
    "            break \n",
    "        last_theta=theta\n",
    "    print(loop_counter, diff)\n",
    "    print('theta',theta)\n",
    "    return diff,theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_ratio_from_policies(sample_trajectories,base_p,execu_p):\n",
    "    ratios=[]\n",
    "    for traj in sample_trajectories:\n",
    "        ratio=1\n",
    "        for i in range(len(traj)-1):\n",
    "            step=traj[i]\n",
    "            next_step=traj[i+1]\n",
    "            try:\n",
    "                grid=str(step[1])+'|'+str(step[2])\n",
    "                action=str(next_step[1])+'|'+str(next_step[2])\n",
    "                ratio+=math.log(base_p[grid][action]/1.0/execu_p[grid][action])\n",
    "            except:\n",
    "                ratio+=0\n",
    "        ratios.append(ratio)\n",
    "    return np.array(ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_matrix(trajectories,features):\n",
    "    feature_matrix=[]\n",
    "    for traj in trajectories:\n",
    "        feature_matrix.append(get_feature_vector(traj,features[0],features[1],features[2]))\n",
    "    return np.array(feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_norm(first,second,norm):\n",
    "    if len(first)!=len(second):\n",
    "        raise(ValueError('Not same length'))\n",
    "    else:\n",
    "        max_norm=0\n",
    "        for i in range(len(first)):\n",
    "            max_norm+=abs(first[i]-second[i])**norm\n",
    "        return max_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class cont_mdp(object):\n",
    "    \"\"\"\n",
    "    MDP example\n",
    "    \"\"\"\n",
    "    def __init__(self,states,actions,state_action):\n",
    "        self.states=states\n",
    "        self.actions=actions\n",
    "        self.state_action=state_action\n",
    "\n",
    "        #generate uniform policy\n",
    "        self.uniform_policy={}\n",
    "        grid_set=set()\n",
    "        for state in self.states:\n",
    "            items=state.split('|')\n",
    "            grid_set.add('|'.join(items[:2]))\n",
    "        grids=list(grid_set)\n",
    "        for grid in grids:\n",
    "            policy={}\n",
    "            grid_l=list(map(int,grid.split('|')))\n",
    "            x=grid_l[0]\n",
    "            y=grid_l[1]\n",
    "            acts=[]\n",
    "            for i in range(-1,2):\n",
    "                for j in range(-1,2):\n",
    "                    acts.append('|'.join(map(str,[x+i,y+j])))\n",
    "            for act in acts:\n",
    "                policy[act]=1/9\n",
    "            self.uniform_policy[grid]=policy\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def trajs_2_states(trajs):\n",
    "    state_set_plates = {}\n",
    "    action_set_plates = {} \n",
    "    for plate in trajs:\n",
    "        state_set=set()\n",
    "        action_set=set()\n",
    "        for traj in trajs[plate]:\n",
    "            for i in range(len(traj)-1):\n",
    "                state='|'.join(map(str,traj[i][1:]))\n",
    "                action='|'.join(map(str,traj[i+1][1:3]))\n",
    "                result='|'.join(map(str,traj[i+1][1:]))\n",
    "                state_set.add(state)\n",
    "                action_set.add(action)\n",
    "                state_set.add(result)\n",
    "#                 print(state)\n",
    "#                 print('--------------------------')\n",
    "#                 print(action)\n",
    "#                 print('--------------------------')\n",
    "#                 print(result)\n",
    "#                 print('--------------------------')\n",
    "#                 print('--------------------------')\n",
    "        state_set_plates[plate] = state_set\n",
    "        action_set_plates[plate] = action_set\n",
    "\n",
    "\n",
    "    states_plates = {}\n",
    "    actions_plates = {}\n",
    "    for plate in state_set_plates:\n",
    "        states=list(state_set_plates[plate])\n",
    "        actions=list(action_set_plates[plate])\n",
    "        states_plates[plate] = states\n",
    "        actions_plates[plate] = actions\n",
    "        \n",
    "    state_index={}\n",
    "    action_index={}\n",
    "    for plate in states_plates:\n",
    "        state_index[plate] = {}\n",
    "        action_index[plate] = {}\n",
    "        for i in range(len(states_plates[plate])):\n",
    "            state_index[plate][states_plates[plate][i]]=i\n",
    "        for i in range(len(actions_plates[plate])):\n",
    "            action_index[plate][actions_plates[plate][i]]=i\n",
    "\n",
    "    state_action_plates={}\n",
    "    for plate in trajs:\n",
    "        state_action_plates[plate] = {}\n",
    "        for traj in trajs[plate]:\n",
    "            for i in range(len(traj)-1):\n",
    "                state='|'.join(map(str,traj[i][1:]))\n",
    "                action='|'.join(map(str,traj[i+1][1:3]))\n",
    "                s_i=state_index[plate][state]\n",
    "                a_i=action_index[plate][action]\n",
    "                if s_i not in state_action_plates[plate]:\n",
    "                    state_action_plates[plate][s_i]=[a_i]\n",
    "                elif a_i not in state_action_plates[plate][s_i]:\n",
    "                    state_action_plates[plate][s_i].append(a_i)\n",
    "    return states_plates, actions_plates, state_action_plates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(month):\n",
    "    trajectories=pickle.load(open(\"D:/Software Engineering/thesis/Driver/mdp_trajs_07.pkl\",'rb'))\n",
    "    states, actions, state_action = trajs_2_states(trajectories)\n",
    "    profile_info = pickle.load(open(\"D:/Software Engineering/thesis/Driver/profile_info.pkl\",'rb'))\n",
    "    [fa,mf,hl,bt] = profile_info\n",
    "    hf = pickle.load(open('D:/Software Engineering/thesis/Driver/profile_info.pkl','rb'))\n",
    "    return states,actions,state_action,trajectories,mf,fa,hl,bt,hf\n",
    "\n",
    "def extract_plate_info(plate,states_plates,actions_plates,state_action_plates,trajectories_plates):\n",
    "    return states_plates[plate],actions_plates[plate],state_action_plates[plate],trajectories_plates[plate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gps2grid(lat,lgt):\n",
    "    return [int((lat-22.44)/0.009)+1,int((lgt-113.75)/0.01)+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_feature_vector(trajectory,hf,mf,fa):\n",
    "    pois = [gps2grid(22.639444, 113.810833),gps2grid(22.534167, 114.111667)]#airport, train station.\n",
    "    feature=np.zeros(11)\n",
    "    plate=trajectory[0][0]\n",
    "    bl=list(map(int,mf[plate].split('|')))\n",
    "    hl=gps2grid(hl_plates[plate][1],hl_plates[plate][0])\n",
    "    bt = bt_plates[plate][0]//(60*5)+1\n",
    "    last_step=[]\n",
    "    for i in range(len(trajectory)):\n",
    "        step=trajectory[i]\n",
    " \n",
    "        ind='|'.join(map(str,step[1:]))\n",
    "  \n",
    "        if ind in fa[plate]:\n",
    "            fml=fa[plate][ind]\n",
    "        else:\n",
    "            fml=0\n",
    "        db=math.sqrt((bl[0]-step[1])**2+(bl[1]-step[2])**2)\n",
    "        dp = [math.sqrt((poi[0]-step[1])**2+(poi[1]-step[2])**2) for poi in pois]\n",
    "        dh = math.sqrt((hl[0]-step[1])**2+(hl[1]-step[2])**2)\n",
    "        dt = step[3] - bt\n",
    "        try:\n",
    "            f=deepcopy(hf[ind])[:-1]\n",
    "        except:\n",
    "            f=[0,0,0,0]\n",
    "        f.extend(dp)\n",
    "        f.extend([fml,db,dh,dt])\n",
    "        if i>0 and last_step[1]==step[1] and last_step[2]==step[2]:\n",
    "            f.append(1)\n",
    "        else:\n",
    "            f.append(0)\n",
    "        fea=np.array(f)\n",
    "        feature+=fea\n",
    "        last_step=step\n",
    "    return feature\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_policy_from_traj(trajs):\n",
    "    raw_counter={}\n",
    "    for traj in trajs:\n",
    "        for i in range(len(traj)-1):\n",
    "            step=traj[i]\n",
    "            next_step=traj[i+1]\n",
    "            x1=step[1]\n",
    "            y1=step[2]\n",
    "            x2=next_step[1]\n",
    "            y2=next_step[2]\n",
    "            if abs(x2-x1)>1 or abs(y2-y1)>1:\n",
    "                continue\n",
    "            grid=str(x1)+'|'+str(y1)\n",
    "            action=str(x2)+'|'+str(y2)\n",
    "            if grid not in raw_counter:\n",
    "                raw_counter[grid]={action:1}\n",
    "            elif action not in raw_counter[grid]:\n",
    "                raw_counter[grid][action]=1\n",
    "            else:\n",
    "                raw_counter[grid][action]+=1\n",
    "    policy={}\n",
    "    for grid in raw_counter:\n",
    "        sum_p=0\n",
    "        policy_grid={}\n",
    "        for action in raw_counter[grid]:\n",
    "            sum_p+=raw_counter[grid][action]\n",
    "        for action in raw_counter[grid]:\n",
    "            policy_grid[action]=raw_counter[grid][action]/1.0/sum_p\n",
    "        policy[grid]=policy_grid\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def match_feature_tr(trajs,hf0,mf0,fa0):\n",
    "    scaler=MinMaxScaler()\n",
    "    scaler_14=MinMaxScaler()\n",
    "    t0_all=[]\n",
    "    features=[]\n",
    "    t14_all=[]\n",
    "    features_14=[]\n",
    "    for traj in trajs:\n",
    "        t0_all.append(traj)\n",
    "        t14_all.append(traj)\n",
    "        fea=get_feature_vector(traj,hf0,mf0,fa0)\n",
    "        features.append(fea)\n",
    "        features_14.append(fea)\n",
    "    feature_matri_14=np.array(features_14)    \n",
    "    scaler_14=scaler_14.fit(feature_matri_14)\n",
    "    print(scaler_14)\n",
    "    return scaler_14,t14_all,feature_matri_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-3c09cdef1714>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmonth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'07'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstates_plates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactions_plates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstate_action_plates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrajectories_plates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmf_plates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfa_plates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhl_plates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbt_plates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msample_plates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrajectories_plates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load' is not defined"
     ]
    }
   ],
   "source": [
    "month = '07'\n",
    "states_plates,actions_plates,state_action_plates,trajectories_plates,mf_plates,fa_plates,hl_plates,bt_plates,hf=load(month=month)\n",
    "\n",
    "sample_plates = list(trajectories_plates.keys())\n",
    "\n",
    "theta_plates_  = {}\n",
    "k = 0\n",
    "t0=datetime.datetime.now()\n",
    "for plate in sample_plates[:]:\n",
    "    k+=1\n",
    "\n",
    "    states_1_plate,actions_1_plate,state_action_1_plate,trajs_1_plate = extract_plate_info(plate,states_plates ,actions_plates ,state_action_plates ,trajectories_plates )\n",
    "    if(len(trajs_1_plate)==0):\n",
    "        print('useless plate:',plate)\n",
    "        continue\n",
    "    exam_mdp_1_plate=cont_mdp(states_1_plate,actions_1_plate,state_action_1_plate)\n",
    "\n",
    "    scaler_ ,t_all,feature_matri_  = match_feature_tr(trajs_1_plate,hf,mf_plates ,fa_plates )\n",
    "    ori_policy_ =get_policy_from_traj(t_all)\n",
    "    tr_fea_ =scaler_ .transform(feature_matri_ )\n",
    "    feature_e_ =sum(tr_fea_ )/len(feature_matri_ )\n",
    "    t1=datetime.datetime.now()\n",
    "    diff_ ,re_ =irl_gradient_ascent(error_term=0,feature_matrix=tr_fea_ ,learning_rate=1,scaler=scaler_ , \\\n",
    "                            feature_e=feature_e_ ,sample_trajectories=t_all,thre=1e-7, \\\n",
    "                    base_p=exam_mdp_1_plate.uniform_policy,execu_p=ori_policy_ ,show_flag=False,show_count=20000)\n",
    "    pickle.dump(re_ ,open('D:/Software Engineering/thesis/Driver/mdp_trajs_07.pkl','wb'))\n",
    "    theta_plates_ [plate] = re_ \n",
    "    print(k,'*******************',(datetime.datetime.now()-t1),(datetime.datetime.now()-t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
